{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        #parameters for Adam optimizer\n",
    "        self.vdb = [np.zeros(b.shape) for b in self.biases]\n",
    "        self.vdw = [np.zeros(w.shape) for w in self.weights]\n",
    "        self.sdb = [np.zeros(b.shape) for b in self.biases]\n",
    "        self.sdw = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def feedforward(self, a,using_soft_max=False):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases[:-1], self.weights[:-1]):\n",
    "            a = sigmoid(np.dot(w, a)+ b)\n",
    "            \n",
    "        b,w = (self.biases[-1],self.weights[-1])\n",
    "        if using_soft_max:\n",
    "            a = soft_max(np.dot(w, a)+ b)\n",
    "        else:\n",
    "            a = sigmoid(np.dot(w, a)+ b)\n",
    "        return a\n",
    "    \n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,test_data=None,using_soft_max = False,using_adam_optimizer = False):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if test_data != None:\n",
    "            n_test = len(test_data)\n",
    "\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            \n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta, j, using_soft_max=using_soft_max,using_adam_optimizer=using_adam_optimizer)\n",
    "            if test_data != None:\n",
    "                print(\"Epoch {0}: {1} / {2}\".format(j, self.evaluate(test_data,using_soft_max), n_test))\n",
    "            else:\n",
    "                print(\"Epoch {0} complete\".format(j))\n",
    "    \n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, eta,epoch,using_soft_max=False,using_adam_optimizer = False):\n",
    "        beta1 = 0.9 \n",
    "        beta2 = 0.999\n",
    "        epsilon = np.array([pow(10, -8)])\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y, soft_max)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        #Adam optimizer\n",
    "        if using_adam_optimizer:\n",
    "            self.vdw = np.array([beta1*vv+(1-beta1)*nw for vv, nw in zip(self.vdw,nabla_w)])\n",
    "            self.vdb = np.array([beta1*bb+(1-beta1)*nb for bb, nb in zip(self.vdb,nabla_b)])\n",
    "            self.sdw = np.array([beta2*ss+(1-beta2)*pow(nw, 2) for ss, nw in zip(self.sdw,nabla_w)])\n",
    "            self.sdb = np.array([beta2*ss+(1-beta2)*pow(nw, 2) for ss, nw in zip(self.sdb,nabla_b)])\n",
    "            vdw_corrected = self.vdw / (1-pow(beta1, epoch+1))\n",
    "            vdb_corrected = self.vdb / (1-pow(beta1, epoch+1))\n",
    "            sdw_corrected = self.sdw / (1-pow(beta2,epoch+1))\n",
    "            sdb_corrected = self.sdb / (1-pow(beta2,epoch+1))\n",
    "            self.weights = [w - (eta * (v_corrected / (np.sqrt(s_corrected)+ epsilon)))\n",
    "                        for w, v_corrected, s_corrected in zip(self.weights,vdw_corrected,sdw_corrected)]\n",
    "            self.biases = [b - (eta * (v_corrected / (np.sqrt(s_corrected)+ epsilon)))\n",
    "                        for b, v_corrected, s_corrected in zip(self.biases,vdb_corrected,sdb_corrected)]\n",
    "        else:     \n",
    "            self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]\n",
    "            self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]\n",
    "    \n",
    "    def backprop(self, x, y, using_soft_max=False,using_cross_entropy = True):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases[:-1], self.weights[:-1]):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        w,b = (self.weights[-1],self.biases[-1])\n",
    "        z = np.dot(w, activation)+b\n",
    "        zs.append(z)\n",
    "        if using_soft_max:\n",
    "            activation = soft_max(z)\n",
    "        else:\n",
    "            activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * soft_max_prime(zs[-1])\n",
    "        if using_cross_entropy:\n",
    "            delta = self.cost_derivative(activations[-1], y)\n",
    "        else:\n",
    "            delta = self.cost_derivative(activations[-1], y) * soft_max_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "    \n",
    "    def evaluate(self, test_data, soft_max):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x,using_soft_max=soft_max)), np.argmax(y)) for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(z):\n",
    "    expA = np.exp(z - np.max(z))\n",
    "    res = expA / expA.sum()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max_prime(z):\n",
    "    return soft_max(z)*(1-soft_max(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Intelligent Systems\n"
     ]
    }
   ],
   "source": [
    "%cd D:\\Intelligent Systems\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_genres=['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalising all features\n",
    "data = pd.read_csv('predictions_cnn.csv')\n",
    "genre_list=[]\n",
    "\n",
    "for row in  data.loc[:,'filename']:\n",
    "    genre_list.append(row.split('.')[0])\n",
    "\n",
    "minMaxScaler = MinMaxScaler()\n",
    "X=minMaxScaler.fit_transform(np.array(data.iloc[:,3:-10], dtype = float))\n",
    "\n",
    "normalised_values_table = pd.concat([data.loc[:,['filename','offset','duration']],\n",
    "                           pd.DataFrame(X,columns=data.columns[3:-10]),\n",
    "                           data.loc[:,supported_genres],\n",
    "                           pd.DataFrame(np.array(genre_list),columns=['genre'])],\n",
    "                           axis=1)\n",
    "normalised_values_table.to_csv('Normalised_Features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating desired output according to genre column in table\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)\n",
    "auxArray = np.array([[1],[0],[0],[0],[0],[0],[0],[0],[0],[0]])\n",
    "desiredOutput = [np.roll(auxArray,x) for x in y]\n",
    "desiredOutput = np.array(desiredOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this part we include which features we want to give to ANN and combine them with predictions\n",
    "USING_PREDICTIONS = True\n",
    "data = pd.read_csv('Normalised_Features.csv')\n",
    "features_selection = ['chroma_stft','spectral_centroid','spectral_bandwidth','rolloff','zero_crossing_rate', 'mfcc']\n",
    "new_feature_table = pd.DataFrame()\n",
    "\n",
    "for feature in features_selection:\n",
    "    if feature != 'mfcc':\n",
    "        new_feature_table = pd.concat([new_feature_table, data.loc[:,[feature]]],axis=1)\n",
    "    else:\n",
    "        new_feature_table = pd.concat([new_feature_table, data.filter(regex=(\"mfcc.*\"))],axis=1)\n",
    "\n",
    "if USING_PREDICTIONS:       \n",
    "    features_and_predictions = pd.concat([new_feature_table,ndata.loc[:,supported_genres]],naxis=1)\n",
    "else:\n",
    "    features_and_predictions = new_feature_table   \n",
    "\n",
    "ANN_NUM_OF_INPUT = len(features_and_predictions.columns)\n",
    "ANN_NUM_OF_OUTPUT = len(supported_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=[]\n",
    "\n",
    "for row_index,row in features_and_predictions.iterrows():\n",
    "    r = np.array(row)\n",
    "    data_set.append(np.reshape(r,(len(row),1)))\n",
    "data_set = [(x,y) for x,y in zip(data_set,desiredOutput)]\n",
    "random.shuffle(data_set)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Network([ANN_NUM_OF_INPUT,20,15,ANN_NUM_OF_OUTPUT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_dataset = data_set[:3000]\n",
    "evaluation_dataset = data_set[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 222 / 1000\n",
      "Epoch 1: 274 / 1000\n",
      "Epoch 2: 321 / 1000\n",
      "Epoch 3: 358 / 1000\n",
      "Epoch 4: 369 / 1000\n",
      "Epoch 5: 360 / 1000\n",
      "Epoch 6: 388 / 1000\n",
      "Epoch 7: 383 / 1000\n",
      "Epoch 8: 387 / 1000\n",
      "Epoch 9: 379 / 1000\n",
      "Epoch 10: 389 / 1000\n",
      "Epoch 11: 399 / 1000\n",
      "Epoch 12: 406 / 1000\n",
      "Epoch 13: 419 / 1000\n",
      "Epoch 14: 413 / 1000\n",
      "Epoch 15: 430 / 1000\n",
      "Epoch 16: 434 / 1000\n",
      "Epoch 17: 433 / 1000\n",
      "Epoch 18: 445 / 1000\n",
      "Epoch 19: 433 / 1000\n",
      "Epoch 20: 450 / 1000\n",
      "Epoch 21: 446 / 1000\n",
      "Epoch 22: 467 / 1000\n",
      "Epoch 23: 455 / 1000\n",
      "Epoch 24: 444 / 1000\n",
      "Epoch 25: 483 / 1000\n",
      "Epoch 26: 440 / 1000\n",
      "Epoch 27: 463 / 1000\n",
      "Epoch 28: 474 / 1000\n",
      "Epoch 29: 472 / 1000\n",
      "Epoch 30: 488 / 1000\n",
      "Epoch 31: 489 / 1000\n",
      "Epoch 32: 458 / 1000\n",
      "Epoch 33: 501 / 1000\n",
      "Epoch 34: 486 / 1000\n",
      "Epoch 35: 473 / 1000\n",
      "Epoch 36: 507 / 1000\n",
      "Epoch 37: 473 / 1000\n",
      "Epoch 38: 497 / 1000\n",
      "Epoch 39: 511 / 1000\n",
      "Epoch 40: 509 / 1000\n",
      "Epoch 41: 512 / 1000\n",
      "Epoch 42: 492 / 1000\n",
      "Epoch 43: 518 / 1000\n",
      "Epoch 44: 499 / 1000\n",
      "Epoch 45: 515 / 1000\n",
      "Epoch 46: 523 / 1000\n",
      "Epoch 47: 520 / 1000\n",
      "Epoch 48: 518 / 1000\n",
      "Epoch 49: 527 / 1000\n",
      "Epoch 50: 511 / 1000\n",
      "Epoch 51: 532 / 1000\n",
      "Epoch 52: 510 / 1000\n",
      "Epoch 53: 538 / 1000\n",
      "Epoch 54: 520 / 1000\n",
      "Epoch 55: 511 / 1000\n",
      "Epoch 56: 523 / 1000\n",
      "Epoch 57: 527 / 1000\n",
      "Epoch 58: 553 / 1000\n",
      "Epoch 59: 540 / 1000\n",
      "Epoch 60: 506 / 1000\n",
      "Epoch 61: 548 / 1000\n",
      "Epoch 62: 540 / 1000\n",
      "Epoch 63: 542 / 1000\n",
      "Epoch 64: 543 / 1000\n",
      "Epoch 65: 555 / 1000\n",
      "Epoch 66: 551 / 1000\n",
      "Epoch 67: 556 / 1000\n",
      "Epoch 68: 559 / 1000\n",
      "Epoch 69: 547 / 1000\n",
      "Epoch 70: 541 / 1000\n",
      "Epoch 71: 552 / 1000\n",
      "Epoch 72: 556 / 1000\n",
      "Epoch 73: 560 / 1000\n",
      "Epoch 74: 548 / 1000\n",
      "Epoch 75: 546 / 1000\n",
      "Epoch 76: 561 / 1000\n",
      "Epoch 77: 560 / 1000\n",
      "Epoch 78: 565 / 1000\n",
      "Epoch 79: 556 / 1000\n",
      "Epoch 80: 554 / 1000\n",
      "Epoch 81: 570 / 1000\n",
      "Epoch 82: 553 / 1000\n",
      "Epoch 83: 568 / 1000\n",
      "Epoch 84: 557 / 1000\n",
      "Epoch 85: 561 / 1000\n",
      "Epoch 86: 535 / 1000\n",
      "Epoch 87: 539 / 1000\n",
      "Epoch 88: 567 / 1000\n",
      "Epoch 89: 567 / 1000\n",
      "Epoch 90: 575 / 1000\n",
      "Epoch 91: 559 / 1000\n",
      "Epoch 92: 560 / 1000\n",
      "Epoch 93: 548 / 1000\n",
      "Epoch 94: 591 / 1000\n",
      "Epoch 95: 605 / 1000\n",
      "Epoch 96: 568 / 1000\n",
      "Epoch 97: 588 / 1000\n",
      "Epoch 98: 565 / 1000\n",
      "Epoch 99: 539 / 1000\n",
      "Epoch 100: 571 / 1000\n",
      "Epoch 101: 575 / 1000\n",
      "Epoch 102: 567 / 1000\n",
      "Epoch 103: 579 / 1000\n",
      "Epoch 104: 583 / 1000\n",
      "Epoch 105: 560 / 1000\n",
      "Epoch 106: 580 / 1000\n",
      "Epoch 107: 552 / 1000\n",
      "Epoch 108: 572 / 1000\n",
      "Epoch 109: 594 / 1000\n",
      "Epoch 110: 546 / 1000\n",
      "Epoch 111: 596 / 1000\n",
      "Epoch 112: 585 / 1000\n",
      "Epoch 113: 581 / 1000\n",
      "Epoch 114: 592 / 1000\n",
      "Epoch 115: 587 / 1000\n",
      "Epoch 116: 596 / 1000\n",
      "Epoch 117: 596 / 1000\n",
      "Epoch 118: 561 / 1000\n",
      "Epoch 119: 581 / 1000\n",
      "Epoch 120: 602 / 1000\n",
      "Epoch 121: 556 / 1000\n",
      "Epoch 122: 591 / 1000\n",
      "Epoch 123: 592 / 1000\n",
      "Epoch 124: 568 / 1000\n",
      "Epoch 125: 578 / 1000\n",
      "Epoch 126: 592 / 1000\n",
      "Epoch 127: 595 / 1000\n",
      "Epoch 128: 587 / 1000\n",
      "Epoch 129: 581 / 1000\n",
      "Epoch 130: 592 / 1000\n",
      "Epoch 131: 587 / 1000\n",
      "Epoch 132: 589 / 1000\n",
      "Epoch 133: 569 / 1000\n",
      "Epoch 134: 576 / 1000\n",
      "Epoch 135: 602 / 1000\n",
      "Epoch 136: 591 / 1000\n",
      "Epoch 137: 597 / 1000\n",
      "Epoch 138: 577 / 1000\n",
      "Epoch 139: 592 / 1000\n",
      "Epoch 140: 578 / 1000\n",
      "Epoch 141: 583 / 1000\n",
      "Epoch 142: 567 / 1000\n",
      "Epoch 143: 603 / 1000\n",
      "Epoch 144: 586 / 1000\n",
      "Epoch 145: 602 / 1000\n",
      "Epoch 146: 573 / 1000\n",
      "Epoch 147: 578 / 1000\n",
      "Epoch 148: 594 / 1000\n",
      "Epoch 149: 588 / 1000\n",
      "Epoch 150: 595 / 1000\n",
      "Epoch 151: 594 / 1000\n",
      "Epoch 152: 593 / 1000\n",
      "Epoch 153: 591 / 1000\n",
      "Epoch 154: 598 / 1000\n",
      "Epoch 155: 587 / 1000\n",
      "Epoch 156: 591 / 1000\n",
      "Epoch 157: 610 / 1000\n",
      "Epoch 158: 612 / 1000\n",
      "Epoch 159: 599 / 1000\n",
      "Epoch 160: 589 / 1000\n",
      "Epoch 161: 602 / 1000\n",
      "Epoch 162: 572 / 1000\n",
      "Epoch 163: 607 / 1000\n",
      "Epoch 164: 593 / 1000\n",
      "Epoch 165: 612 / 1000\n",
      "Epoch 166: 598 / 1000\n",
      "Epoch 167: 588 / 1000\n",
      "Epoch 168: 619 / 1000\n",
      "Epoch 169: 608 / 1000\n",
      "Epoch 170: 579 / 1000\n",
      "Epoch 171: 605 / 1000\n",
      "Epoch 172: 601 / 1000\n",
      "Epoch 173: 594 / 1000\n",
      "Epoch 174: 597 / 1000\n",
      "Epoch 175: 592 / 1000\n",
      "Epoch 176: 604 / 1000\n",
      "Epoch 177: 578 / 1000\n",
      "Epoch 178: 596 / 1000\n",
      "Epoch 179: 592 / 1000\n",
      "Epoch 180: 591 / 1000\n",
      "Epoch 181: 593 / 1000\n",
      "Epoch 182: 602 / 1000\n",
      "Epoch 183: 600 / 1000\n",
      "Epoch 184: 600 / 1000\n",
      "Epoch 185: 599 / 1000\n",
      "Epoch 186: 598 / 1000\n",
      "Epoch 187: 615 / 1000\n",
      "Epoch 188: 617 / 1000\n",
      "Epoch 189: 598 / 1000\n",
      "Epoch 190: 611 / 1000\n",
      "Epoch 191: 615 / 1000\n",
      "Epoch 192: 599 / 1000\n",
      "Epoch 193: 615 / 1000\n",
      "Epoch 194: 599 / 1000\n",
      "Epoch 195: 605 / 1000\n",
      "Epoch 196: 592 / 1000\n",
      "Epoch 197: 577 / 1000\n",
      "Epoch 198: 571 / 1000\n",
      "Epoch 199: 586 / 1000\n",
      "Epoch 200: 587 / 1000\n",
      "Epoch 201: 563 / 1000\n",
      "Epoch 202: 593 / 1000\n",
      "Epoch 203: 586 / 1000\n",
      "Epoch 204: 608 / 1000\n",
      "Epoch 205: 573 / 1000\n",
      "Epoch 206: 583 / 1000\n",
      "Epoch 207: 582 / 1000\n",
      "Epoch 208: 547 / 1000\n",
      "Epoch 209: 584 / 1000\n",
      "Epoch 210: 544 / 1000\n",
      "Epoch 211: 590 / 1000\n",
      "Epoch 212: 583 / 1000\n",
      "Epoch 213: 589 / 1000\n",
      "Epoch 214: 594 / 1000\n",
      "Epoch 215: 606 / 1000\n",
      "Epoch 216: 600 / 1000\n",
      "Epoch 217: 601 / 1000\n",
      "Epoch 218: 588 / 1000\n",
      "Epoch 219: 595 / 1000\n",
      "Epoch 220: 617 / 1000\n",
      "Epoch 221: 593 / 1000\n",
      "Epoch 222: 590 / 1000\n",
      "Epoch 223: 590 / 1000\n",
      "Epoch 224: 607 / 1000\n",
      "Epoch 225: 599 / 1000\n",
      "Epoch 226: 601 / 1000\n",
      "Epoch 227: 592 / 1000\n",
      "Epoch 228: 602 / 1000\n",
      "Epoch 229: 558 / 1000\n",
      "Epoch 230: 614 / 1000\n",
      "Epoch 231: 598 / 1000\n",
      "Epoch 232: 611 / 1000\n",
      "Epoch 233: 583 / 1000\n",
      "Epoch 234: 598 / 1000\n",
      "Epoch 235: 606 / 1000\n",
      "Epoch 236: 589 / 1000\n",
      "Epoch 237: 601 / 1000\n",
      "Epoch 238: 603 / 1000\n",
      "Epoch 239: 610 / 1000\n",
      "Epoch 240: 622 / 1000\n",
      "Epoch 241: 613 / 1000\n",
      "Epoch 242: 606 / 1000\n",
      "Epoch 243: 590 / 1000\n",
      "Epoch 244: 599 / 1000\n",
      "Epoch 245: 604 / 1000\n",
      "Epoch 246: 606 / 1000\n",
      "Epoch 247: 584 / 1000\n",
      "Epoch 248: 619 / 1000\n",
      "Epoch 249: 607 / 1000\n",
      "Epoch 250: 599 / 1000\n",
      "Epoch 251: 592 / 1000\n",
      "Epoch 252: 607 / 1000\n",
      "Epoch 253: 600 / 1000\n",
      "Epoch 254: 588 / 1000\n",
      "Epoch 255: 590 / 1000\n",
      "Epoch 256: 619 / 1000\n",
      "Epoch 257: 586 / 1000\n",
      "Epoch 258: 609 / 1000\n",
      "Epoch 259: 627 / 1000\n",
      "Epoch 260: 601 / 1000\n",
      "Epoch 261: 611 / 1000\n",
      "Epoch 262: 583 / 1000\n",
      "Epoch 263: 595 / 1000\n",
      "Epoch 264: 582 / 1000\n",
      "Epoch 265: 601 / 1000\n",
      "Epoch 266: 578 / 1000\n",
      "Epoch 267: 601 / 1000\n",
      "Epoch 268: 611 / 1000\n",
      "Epoch 269: 604 / 1000\n",
      "Epoch 270: 610 / 1000\n",
      "Epoch 271: 593 / 1000\n",
      "Epoch 272: 581 / 1000\n",
      "Epoch 273: 576 / 1000\n",
      "Epoch 274: 594 / 1000\n",
      "Epoch 275: 578 / 1000\n",
      "Epoch 276: 590 / 1000\n",
      "Epoch 277: 593 / 1000\n",
      "Epoch 278: 578 / 1000\n",
      "Epoch 279: 585 / 1000\n",
      "Epoch 280: 617 / 1000\n",
      "Epoch 281: 599 / 1000\n",
      "Epoch 282: 603 / 1000\n",
      "Epoch 283: 595 / 1000\n",
      "Epoch 284: 602 / 1000\n",
      "Epoch 285: 578 / 1000\n",
      "Epoch 286: 605 / 1000\n",
      "Epoch 287: 599 / 1000\n",
      "Epoch 288: 612 / 1000\n",
      "Epoch 289: 607 / 1000\n",
      "Epoch 290: 619 / 1000\n",
      "Epoch 291: 598 / 1000\n",
      "Epoch 292: 612 / 1000\n",
      "Epoch 293: 602 / 1000\n",
      "Epoch 294: 603 / 1000\n",
      "Epoch 295: 612 / 1000\n",
      "Epoch 296: 593 / 1000\n",
      "Epoch 297: 604 / 1000\n",
      "Epoch 298: 595 / 1000\n",
      "Epoch 299: 595 / 1000\n",
      "Epoch 300: 607 / 1000\n",
      "Epoch 301: 600 / 1000\n",
      "Epoch 302: 592 / 1000\n",
      "Epoch 303: 603 / 1000\n",
      "Epoch 304: 615 / 1000\n",
      "Epoch 305: 606 / 1000\n",
      "Epoch 306: 606 / 1000\n",
      "Epoch 307: 617 / 1000\n",
      "Epoch 308: 606 / 1000\n",
      "Epoch 309: 598 / 1000\n",
      "Epoch 310: 593 / 1000\n",
      "Epoch 311: 623 / 1000\n",
      "Epoch 312: 609 / 1000\n",
      "Epoch 313: 605 / 1000\n",
      "Epoch 314: 612 / 1000\n",
      "Epoch 315: 606 / 1000\n",
      "Epoch 316: 614 / 1000\n",
      "Epoch 317: 609 / 1000\n",
      "Epoch 318: 616 / 1000\n",
      "Epoch 319: 586 / 1000\n",
      "Epoch 320: 605 / 1000\n",
      "Epoch 321: 620 / 1000\n",
      "Epoch 322: 612 / 1000\n",
      "Epoch 323: 599 / 1000\n",
      "Epoch 324: 602 / 1000\n",
      "Epoch 325: 604 / 1000\n",
      "Epoch 326: 629 / 1000\n",
      "Epoch 327: 622 / 1000\n",
      "Epoch 328: 600 / 1000\n",
      "Epoch 329: 623 / 1000\n",
      "Epoch 330: 601 / 1000\n",
      "Epoch 331: 609 / 1000\n",
      "Epoch 332: 616 / 1000\n",
      "Epoch 333: 617 / 1000\n",
      "Epoch 334: 618 / 1000\n",
      "Epoch 335: 622 / 1000\n",
      "Epoch 336: 602 / 1000\n",
      "Epoch 337: 603 / 1000\n",
      "Epoch 338: 608 / 1000\n",
      "Epoch 339: 609 / 1000\n",
      "Epoch 340: 592 / 1000\n",
      "Epoch 341: 607 / 1000\n",
      "Epoch 342: 628 / 1000\n",
      "Epoch 343: 604 / 1000\n",
      "Epoch 344: 595 / 1000\n",
      "Epoch 345: 617 / 1000\n",
      "Epoch 346: 608 / 1000\n",
      "Epoch 347: 611 / 1000\n",
      "Epoch 348: 609 / 1000\n",
      "Epoch 349: 614 / 1000\n",
      "Epoch 350: 596 / 1000\n",
      "Epoch 351: 609 / 1000\n",
      "Epoch 352: 605 / 1000\n",
      "Epoch 353: 592 / 1000\n",
      "Epoch 354: 603 / 1000\n",
      "Epoch 355: 632 / 1000\n",
      "Epoch 356: 605 / 1000\n",
      "Epoch 357: 601 / 1000\n",
      "Epoch 358: 591 / 1000\n",
      "Epoch 359: 617 / 1000\n",
      "Epoch 360: 611 / 1000\n",
      "Epoch 361: 615 / 1000\n",
      "Epoch 362: 610 / 1000\n",
      "Epoch 363: 616 / 1000\n",
      "Epoch 364: 605 / 1000\n",
      "Epoch 365: 617 / 1000\n",
      "Epoch 366: 589 / 1000\n",
      "Epoch 367: 599 / 1000\n",
      "Epoch 368: 618 / 1000\n",
      "Epoch 369: 614 / 1000\n",
      "Epoch 370: 610 / 1000\n",
      "Epoch 371: 588 / 1000\n",
      "Epoch 372: 621 / 1000\n",
      "Epoch 373: 616 / 1000\n",
      "Epoch 374: 625 / 1000\n",
      "Epoch 375: 612 / 1000\n",
      "Epoch 376: 599 / 1000\n",
      "Epoch 377: 605 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378: 627 / 1000\n",
      "Epoch 379: 620 / 1000\n",
      "Epoch 380: 618 / 1000\n",
      "Epoch 381: 601 / 1000\n",
      "Epoch 382: 600 / 1000\n",
      "Epoch 383: 596 / 1000\n",
      "Epoch 384: 610 / 1000\n",
      "Epoch 385: 589 / 1000\n",
      "Epoch 386: 577 / 1000\n",
      "Epoch 387: 606 / 1000\n",
      "Epoch 388: 605 / 1000\n",
      "Epoch 389: 598 / 1000\n",
      "Epoch 390: 602 / 1000\n",
      "Epoch 391: 603 / 1000\n",
      "Epoch 392: 608 / 1000\n",
      "Epoch 393: 620 / 1000\n",
      "Epoch 394: 607 / 1000\n",
      "Epoch 395: 608 / 1000\n",
      "Epoch 396: 617 / 1000\n",
      "Epoch 397: 613 / 1000\n",
      "Epoch 398: 622 / 1000\n",
      "Epoch 399: 614 / 1000\n",
      "Epoch 400: 616 / 1000\n",
      "Epoch 401: 621 / 1000\n",
      "Epoch 402: 595 / 1000\n",
      "Epoch 403: 616 / 1000\n",
      "Epoch 404: 594 / 1000\n",
      "Epoch 405: 599 / 1000\n",
      "Epoch 406: 614 / 1000\n",
      "Epoch 407: 605 / 1000\n",
      "Epoch 408: 603 / 1000\n",
      "Epoch 409: 618 / 1000\n",
      "Epoch 410: 610 / 1000\n",
      "Epoch 411: 604 / 1000\n",
      "Epoch 412: 607 / 1000\n",
      "Epoch 413: 615 / 1000\n",
      "Epoch 414: 615 / 1000\n",
      "Epoch 415: 619 / 1000\n",
      "Epoch 416: 609 / 1000\n",
      "Epoch 417: 634 / 1000\n",
      "Epoch 418: 614 / 1000\n",
      "Epoch 419: 624 / 1000\n",
      "Epoch 420: 623 / 1000\n",
      "Epoch 421: 618 / 1000\n",
      "Epoch 422: 623 / 1000\n",
      "Epoch 423: 592 / 1000\n",
      "Epoch 424: 605 / 1000\n",
      "Epoch 425: 628 / 1000\n",
      "Epoch 426: 604 / 1000\n",
      "Epoch 427: 603 / 1000\n",
      "Epoch 428: 606 / 1000\n",
      "Epoch 429: 627 / 1000\n",
      "Epoch 430: 605 / 1000\n",
      "Epoch 431: 613 / 1000\n",
      "Epoch 432: 608 / 1000\n",
      "Epoch 433: 602 / 1000\n",
      "Epoch 434: 606 / 1000\n",
      "Epoch 435: 625 / 1000\n",
      "Epoch 436: 600 / 1000\n",
      "Epoch 437: 605 / 1000\n",
      "Epoch 438: 609 / 1000\n",
      "Epoch 439: 622 / 1000\n",
      "Epoch 440: 621 / 1000\n",
      "Epoch 441: 612 / 1000\n",
      "Epoch 442: 595 / 1000\n",
      "Epoch 443: 625 / 1000\n",
      "Epoch 444: 614 / 1000\n",
      "Epoch 445: 597 / 1000\n",
      "Epoch 446: 608 / 1000\n",
      "Epoch 447: 620 / 1000\n",
      "Epoch 448: 621 / 1000\n",
      "Epoch 449: 603 / 1000\n",
      "Epoch 450: 610 / 1000\n",
      "Epoch 451: 596 / 1000\n",
      "Epoch 452: 610 / 1000\n",
      "Epoch 453: 602 / 1000\n",
      "Epoch 454: 641 / 1000\n",
      "Epoch 455: 623 / 1000\n",
      "Epoch 456: 615 / 1000\n",
      "Epoch 457: 614 / 1000\n",
      "Epoch 458: 626 / 1000\n",
      "Epoch 459: 622 / 1000\n",
      "Epoch 460: 604 / 1000\n",
      "Epoch 461: 615 / 1000\n",
      "Epoch 462: 621 / 1000\n",
      "Epoch 463: 622 / 1000\n",
      "Epoch 464: 618 / 1000\n",
      "Epoch 465: 615 / 1000\n",
      "Epoch 466: 624 / 1000\n",
      "Epoch 467: 618 / 1000\n",
      "Epoch 468: 617 / 1000\n",
      "Epoch 469: 609 / 1000\n",
      "Epoch 470: 601 / 1000\n",
      "Epoch 471: 619 / 1000\n",
      "Epoch 472: 606 / 1000\n",
      "Epoch 473: 619 / 1000\n",
      "Epoch 474: 607 / 1000\n",
      "Epoch 475: 622 / 1000\n",
      "Epoch 476: 596 / 1000\n",
      "Epoch 477: 606 / 1000\n",
      "Epoch 478: 621 / 1000\n",
      "Epoch 479: 621 / 1000\n",
      "Epoch 480: 618 / 1000\n",
      "Epoch 481: 596 / 1000\n",
      "Epoch 482: 634 / 1000\n",
      "Epoch 483: 616 / 1000\n",
      "Epoch 484: 616 / 1000\n",
      "Epoch 485: 600 / 1000\n",
      "Epoch 486: 626 / 1000\n",
      "Epoch 487: 614 / 1000\n",
      "Epoch 488: 607 / 1000\n",
      "Epoch 489: 615 / 1000\n",
      "Epoch 490: 623 / 1000\n",
      "Epoch 491: 629 / 1000\n",
      "Epoch 492: 614 / 1000\n",
      "Epoch 493: 623 / 1000\n",
      "Epoch 494: 616 / 1000\n",
      "Epoch 495: 631 / 1000\n",
      "Epoch 496: 625 / 1000\n",
      "Epoch 497: 610 / 1000\n",
      "Epoch 498: 593 / 1000\n",
      "Epoch 499: 618 / 1000\n",
      "Epoch 500: 608 / 1000\n",
      "Epoch 501: 619 / 1000\n",
      "Epoch 502: 602 / 1000\n",
      "Epoch 503: 604 / 1000\n",
      "Epoch 504: 606 / 1000\n",
      "Epoch 505: 617 / 1000\n",
      "Epoch 506: 622 / 1000\n",
      "Epoch 507: 633 / 1000\n",
      "Epoch 508: 615 / 1000\n",
      "Epoch 509: 618 / 1000\n",
      "Epoch 510: 625 / 1000\n",
      "Epoch 511: 604 / 1000\n",
      "Epoch 512: 623 / 1000\n",
      "Epoch 513: 609 / 1000\n",
      "Epoch 514: 609 / 1000\n",
      "Epoch 515: 632 / 1000\n",
      "Epoch 516: 625 / 1000\n",
      "Epoch 517: 615 / 1000\n",
      "Epoch 518: 593 / 1000\n",
      "Epoch 519: 601 / 1000\n",
      "Epoch 520: 586 / 1000\n",
      "Epoch 521: 610 / 1000\n",
      "Epoch 522: 625 / 1000\n",
      "Epoch 523: 608 / 1000\n",
      "Epoch 524: 622 / 1000\n",
      "Epoch 525: 617 / 1000\n",
      "Epoch 526: 617 / 1000\n",
      "Epoch 527: 607 / 1000\n",
      "Epoch 528: 606 / 1000\n",
      "Epoch 529: 622 / 1000\n",
      "Epoch 530: 608 / 1000\n",
      "Epoch 531: 603 / 1000\n",
      "Epoch 532: 598 / 1000\n",
      "Epoch 533: 615 / 1000\n",
      "Epoch 534: 602 / 1000\n",
      "Epoch 535: 608 / 1000\n",
      "Epoch 536: 622 / 1000\n",
      "Epoch 537: 613 / 1000\n",
      "Epoch 538: 617 / 1000\n",
      "Epoch 539: 608 / 1000\n",
      "Epoch 540: 619 / 1000\n",
      "Epoch 541: 625 / 1000\n",
      "Epoch 542: 609 / 1000\n",
      "Epoch 543: 609 / 1000\n",
      "Epoch 544: 624 / 1000\n",
      "Epoch 545: 577 / 1000\n",
      "Epoch 546: 619 / 1000\n",
      "Epoch 547: 625 / 1000\n",
      "Epoch 548: 597 / 1000\n",
      "Epoch 549: 615 / 1000\n",
      "Epoch 550: 618 / 1000\n",
      "Epoch 551: 626 / 1000\n",
      "Epoch 552: 617 / 1000\n",
      "Epoch 553: 615 / 1000\n",
      "Epoch 554: 594 / 1000\n",
      "Epoch 555: 608 / 1000\n",
      "Epoch 556: 612 / 1000\n",
      "Epoch 557: 623 / 1000\n",
      "Epoch 558: 609 / 1000\n",
      "Epoch 559: 616 / 1000\n",
      "Epoch 560: 606 / 1000\n",
      "Epoch 561: 604 / 1000\n",
      "Epoch 562: 628 / 1000\n",
      "Epoch 563: 633 / 1000\n",
      "Epoch 564: 606 / 1000\n",
      "Epoch 565: 591 / 1000\n",
      "Epoch 566: 603 / 1000\n",
      "Epoch 567: 591 / 1000\n",
      "Epoch 568: 604 / 1000\n",
      "Epoch 569: 599 / 1000\n",
      "Epoch 570: 611 / 1000\n",
      "Epoch 571: 620 / 1000\n",
      "Epoch 572: 619 / 1000\n",
      "Epoch 573: 610 / 1000\n",
      "Epoch 574: 617 / 1000\n",
      "Epoch 575: 614 / 1000\n",
      "Epoch 576: 614 / 1000\n",
      "Epoch 577: 614 / 1000\n",
      "Epoch 578: 622 / 1000\n",
      "Epoch 579: 610 / 1000\n",
      "Epoch 580: 620 / 1000\n",
      "Epoch 581: 607 / 1000\n",
      "Epoch 582: 618 / 1000\n",
      "Epoch 583: 606 / 1000\n",
      "Epoch 584: 593 / 1000\n",
      "Epoch 585: 598 / 1000\n",
      "Epoch 586: 617 / 1000\n",
      "Epoch 587: 621 / 1000\n",
      "Epoch 588: 619 / 1000\n",
      "Epoch 589: 615 / 1000\n",
      "Epoch 590: 606 / 1000\n",
      "Epoch 591: 599 / 1000\n",
      "Epoch 592: 604 / 1000\n",
      "Epoch 593: 610 / 1000\n",
      "Epoch 594: 607 / 1000\n",
      "Epoch 595: 603 / 1000\n",
      "Epoch 596: 615 / 1000\n",
      "Epoch 597: 601 / 1000\n",
      "Epoch 598: 610 / 1000\n",
      "Epoch 599: 634 / 1000\n",
      "Epoch 600: 620 / 1000\n",
      "Epoch 601: 607 / 1000\n",
      "Epoch 602: 621 / 1000\n",
      "Epoch 603: 613 / 1000\n",
      "Epoch 604: 619 / 1000\n",
      "Epoch 605: 615 / 1000\n",
      "Epoch 606: 642 / 1000\n",
      "Epoch 607: 624 / 1000\n",
      "Epoch 608: 610 / 1000\n",
      "Epoch 609: 603 / 1000\n",
      "Epoch 610: 596 / 1000\n",
      "Epoch 611: 590 / 1000\n",
      "Epoch 612: 598 / 1000\n",
      "Epoch 613: 608 / 1000\n",
      "Epoch 614: 608 / 1000\n",
      "Epoch 615: 602 / 1000\n",
      "Epoch 616: 623 / 1000\n",
      "Epoch 617: 610 / 1000\n",
      "Epoch 618: 607 / 1000\n",
      "Epoch 619: 615 / 1000\n",
      "Epoch 620: 621 / 1000\n",
      "Epoch 621: 624 / 1000\n",
      "Epoch 622: 609 / 1000\n",
      "Epoch 623: 605 / 1000\n",
      "Epoch 624: 616 / 1000\n",
      "Epoch 625: 599 / 1000\n",
      "Epoch 626: 607 / 1000\n",
      "Epoch 627: 616 / 1000\n",
      "Epoch 628: 601 / 1000\n",
      "Epoch 629: 599 / 1000\n",
      "Epoch 630: 626 / 1000\n",
      "Epoch 631: 616 / 1000\n",
      "Epoch 632: 634 / 1000\n",
      "Epoch 633: 618 / 1000\n",
      "Epoch 634: 616 / 1000\n",
      "Epoch 635: 609 / 1000\n",
      "Epoch 636: 610 / 1000\n",
      "Epoch 637: 610 / 1000\n",
      "Epoch 638: 583 / 1000\n",
      "Epoch 639: 608 / 1000\n",
      "Epoch 640: 615 / 1000\n",
      "Epoch 641: 606 / 1000\n",
      "Epoch 642: 600 / 1000\n",
      "Epoch 643: 613 / 1000\n",
      "Epoch 644: 607 / 1000\n",
      "Epoch 645: 624 / 1000\n",
      "Epoch 646: 599 / 1000\n",
      "Epoch 647: 626 / 1000\n",
      "Epoch 648: 576 / 1000\n",
      "Epoch 649: 594 / 1000\n",
      "Epoch 650: 618 / 1000\n",
      "Epoch 651: 604 / 1000\n",
      "Epoch 652: 622 / 1000\n",
      "Epoch 653: 624 / 1000\n",
      "Epoch 654: 620 / 1000\n",
      "Epoch 655: 607 / 1000\n",
      "Epoch 656: 603 / 1000\n",
      "Epoch 657: 622 / 1000\n",
      "Epoch 658: 588 / 1000\n",
      "Epoch 659: 599 / 1000\n",
      "Epoch 660: 607 / 1000\n",
      "Epoch 661: 612 / 1000\n",
      "Epoch 662: 628 / 1000\n",
      "Epoch 663: 604 / 1000\n",
      "Epoch 664: 617 / 1000\n",
      "Epoch 665: 611 / 1000\n",
      "Epoch 666: 610 / 1000\n",
      "Epoch 667: 607 / 1000\n",
      "Epoch 668: 628 / 1000\n",
      "Epoch 669: 610 / 1000\n",
      "Epoch 670: 608 / 1000\n",
      "Epoch 671: 609 / 1000\n",
      "Epoch 672: 615 / 1000\n",
      "Epoch 673: 603 / 1000\n",
      "Epoch 674: 618 / 1000\n",
      "Epoch 675: 614 / 1000\n",
      "Epoch 676: 604 / 1000\n",
      "Epoch 677: 610 / 1000\n",
      "Epoch 678: 618 / 1000\n",
      "Epoch 679: 610 / 1000\n",
      "Epoch 680: 608 / 1000\n",
      "Epoch 681: 596 / 1000\n",
      "Epoch 682: 599 / 1000\n",
      "Epoch 683: 600 / 1000\n",
      "Epoch 684: 582 / 1000\n",
      "Epoch 685: 603 / 1000\n",
      "Epoch 686: 611 / 1000\n",
      "Epoch 687: 623 / 1000\n",
      "Epoch 688: 618 / 1000\n",
      "Epoch 689: 598 / 1000\n",
      "Epoch 690: 613 / 1000\n",
      "Epoch 691: 611 / 1000\n",
      "Epoch 692: 591 / 1000\n",
      "Epoch 693: 618 / 1000\n",
      "Epoch 694: 620 / 1000\n",
      "Epoch 695: 604 / 1000\n",
      "Epoch 696: 621 / 1000\n",
      "Epoch 697: 610 / 1000\n",
      "Epoch 698: 604 / 1000\n",
      "Epoch 699: 605 / 1000\n",
      "Epoch 700: 601 / 1000\n",
      "Epoch 701: 616 / 1000\n",
      "Epoch 702: 615 / 1000\n",
      "Epoch 703: 620 / 1000\n",
      "Epoch 704: 599 / 1000\n",
      "Epoch 705: 597 / 1000\n",
      "Epoch 706: 610 / 1000\n",
      "Epoch 707: 605 / 1000\n",
      "Epoch 708: 612 / 1000\n",
      "Epoch 709: 599 / 1000\n",
      "Epoch 710: 596 / 1000\n",
      "Epoch 711: 586 / 1000\n",
      "Epoch 712: 603 / 1000\n",
      "Epoch 713: 604 / 1000\n",
      "Epoch 714: 600 / 1000\n",
      "Epoch 715: 609 / 1000\n",
      "Epoch 716: 609 / 1000\n",
      "Epoch 717: 604 / 1000\n",
      "Epoch 718: 581 / 1000\n",
      "Epoch 719: 595 / 1000\n",
      "Epoch 720: 605 / 1000\n",
      "Epoch 721: 580 / 1000\n",
      "Epoch 722: 588 / 1000\n",
      "Epoch 723: 601 / 1000\n",
      "Epoch 724: 599 / 1000\n",
      "Epoch 725: 609 / 1000\n",
      "Epoch 726: 596 / 1000\n",
      "Epoch 727: 606 / 1000\n",
      "Epoch 728: 616 / 1000\n",
      "Epoch 729: 599 / 1000\n",
      "Epoch 730: 612 / 1000\n",
      "Epoch 731: 616 / 1000\n",
      "Epoch 732: 611 / 1000\n",
      "Epoch 733: 594 / 1000\n",
      "Epoch 734: 604 / 1000\n",
      "Epoch 735: 610 / 1000\n",
      "Epoch 736: 598 / 1000\n",
      "Epoch 737: 612 / 1000\n",
      "Epoch 738: 603 / 1000\n",
      "Epoch 739: 610 / 1000\n",
      "Epoch 740: 603 / 1000\n",
      "Epoch 741: 583 / 1000\n",
      "Epoch 742: 617 / 1000\n",
      "Epoch 743: 613 / 1000\n",
      "Epoch 744: 606 / 1000\n",
      "Epoch 745: 607 / 1000\n",
      "Epoch 746: 611 / 1000\n",
      "Epoch 747: 598 / 1000\n",
      "Epoch 748: 603 / 1000\n",
      "Epoch 749: 610 / 1000\n",
      "Epoch 750: 590 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751: 601 / 1000\n",
      "Epoch 752: 619 / 1000\n",
      "Epoch 753: 617 / 1000\n",
      "Epoch 754: 599 / 1000\n",
      "Epoch 755: 612 / 1000\n",
      "Epoch 756: 602 / 1000\n",
      "Epoch 757: 605 / 1000\n",
      "Epoch 758: 581 / 1000\n",
      "Epoch 759: 591 / 1000\n",
      "Epoch 760: 612 / 1000\n",
      "Epoch 761: 624 / 1000\n",
      "Epoch 762: 603 / 1000\n",
      "Epoch 763: 621 / 1000\n",
      "Epoch 764: 600 / 1000\n",
      "Epoch 765: 612 / 1000\n",
      "Epoch 766: 616 / 1000\n",
      "Epoch 767: 601 / 1000\n",
      "Epoch 768: 601 / 1000\n",
      "Epoch 769: 601 / 1000\n",
      "Epoch 770: 624 / 1000\n",
      "Epoch 771: 613 / 1000\n",
      "Epoch 772: 584 / 1000\n",
      "Epoch 773: 603 / 1000\n",
      "Epoch 774: 591 / 1000\n",
      "Epoch 775: 598 / 1000\n",
      "Epoch 776: 600 / 1000\n",
      "Epoch 777: 629 / 1000\n",
      "Epoch 778: 587 / 1000\n",
      "Epoch 779: 586 / 1000\n",
      "Epoch 780: 611 / 1000\n",
      "Epoch 781: 588 / 1000\n",
      "Epoch 782: 601 / 1000\n",
      "Epoch 783: 592 / 1000\n",
      "Epoch 784: 602 / 1000\n",
      "Epoch 785: 604 / 1000\n",
      "Epoch 786: 609 / 1000\n",
      "Epoch 787: 593 / 1000\n",
      "Epoch 788: 600 / 1000\n",
      "Epoch 789: 601 / 1000\n",
      "Epoch 790: 611 / 1000\n",
      "Epoch 791: 598 / 1000\n",
      "Epoch 792: 599 / 1000\n",
      "Epoch 793: 594 / 1000\n",
      "Epoch 794: 597 / 1000\n",
      "Epoch 795: 605 / 1000\n",
      "Epoch 796: 615 / 1000\n",
      "Epoch 797: 598 / 1000\n",
      "Epoch 798: 607 / 1000\n",
      "Epoch 799: 603 / 1000\n",
      "Epoch 800: 590 / 1000\n",
      "Epoch 801: 602 / 1000\n",
      "Epoch 802: 610 / 1000\n",
      "Epoch 803: 581 / 1000\n",
      "Epoch 804: 591 / 1000\n",
      "Epoch 805: 614 / 1000\n",
      "Epoch 806: 604 / 1000\n",
      "Epoch 807: 610 / 1000\n",
      "Epoch 808: 594 / 1000\n",
      "Epoch 809: 605 / 1000\n",
      "Epoch 810: 598 / 1000\n",
      "Epoch 811: 609 / 1000\n",
      "Epoch 812: 592 / 1000\n",
      "Epoch 813: 603 / 1000\n",
      "Epoch 814: 606 / 1000\n",
      "Epoch 815: 603 / 1000\n",
      "Epoch 816: 594 / 1000\n",
      "Epoch 817: 606 / 1000\n",
      "Epoch 818: 608 / 1000\n",
      "Epoch 819: 607 / 1000\n",
      "Epoch 820: 596 / 1000\n",
      "Epoch 821: 594 / 1000\n",
      "Epoch 822: 594 / 1000\n",
      "Epoch 823: 608 / 1000\n",
      "Epoch 824: 608 / 1000\n",
      "Epoch 825: 581 / 1000\n",
      "Epoch 826: 601 / 1000\n",
      "Epoch 827: 604 / 1000\n",
      "Epoch 828: 610 / 1000\n",
      "Epoch 829: 614 / 1000\n",
      "Epoch 830: 603 / 1000\n",
      "Epoch 831: 587 / 1000\n",
      "Epoch 832: 616 / 1000\n",
      "Epoch 833: 572 / 1000\n",
      "Epoch 834: 614 / 1000\n",
      "Epoch 835: 590 / 1000\n",
      "Epoch 836: 605 / 1000\n",
      "Epoch 837: 610 / 1000\n",
      "Epoch 838: 564 / 1000\n",
      "Epoch 839: 598 / 1000\n",
      "Epoch 840: 589 / 1000\n",
      "Epoch 841: 601 / 1000\n",
      "Epoch 842: 607 / 1000\n",
      "Epoch 843: 620 / 1000\n",
      "Epoch 844: 602 / 1000\n",
      "Epoch 845: 607 / 1000\n",
      "Epoch 846: 604 / 1000\n",
      "Epoch 847: 595 / 1000\n",
      "Epoch 848: 612 / 1000\n",
      "Epoch 849: 600 / 1000\n",
      "Epoch 850: 607 / 1000\n",
      "Epoch 851: 603 / 1000\n",
      "Epoch 852: 602 / 1000\n",
      "Epoch 853: 616 / 1000\n",
      "Epoch 854: 592 / 1000\n",
      "Epoch 855: 602 / 1000\n",
      "Epoch 856: 597 / 1000\n",
      "Epoch 857: 605 / 1000\n",
      "Epoch 858: 604 / 1000\n",
      "Epoch 859: 584 / 1000\n",
      "Epoch 860: 590 / 1000\n",
      "Epoch 861: 602 / 1000\n",
      "Epoch 862: 608 / 1000\n",
      "Epoch 863: 613 / 1000\n",
      "Epoch 864: 587 / 1000\n",
      "Epoch 865: 611 / 1000\n",
      "Epoch 866: 571 / 1000\n",
      "Epoch 867: 582 / 1000\n",
      "Epoch 868: 619 / 1000\n",
      "Epoch 869: 596 / 1000\n",
      "Epoch 870: 598 / 1000\n",
      "Epoch 871: 610 / 1000\n",
      "Epoch 872: 591 / 1000\n",
      "Epoch 873: 608 / 1000\n",
      "Epoch 874: 599 / 1000\n",
      "Epoch 875: 600 / 1000\n",
      "Epoch 876: 606 / 1000\n",
      "Epoch 877: 590 / 1000\n",
      "Epoch 878: 608 / 1000\n",
      "Epoch 879: 610 / 1000\n",
      "Epoch 880: 597 / 1000\n",
      "Epoch 881: 585 / 1000\n",
      "Epoch 882: 602 / 1000\n",
      "Epoch 883: 597 / 1000\n",
      "Epoch 884: 593 / 1000\n",
      "Epoch 885: 605 / 1000\n",
      "Epoch 886: 609 / 1000\n",
      "Epoch 887: 587 / 1000\n",
      "Epoch 888: 596 / 1000\n",
      "Epoch 889: 582 / 1000\n",
      "Epoch 890: 591 / 1000\n",
      "Epoch 891: 598 / 1000\n",
      "Epoch 892: 607 / 1000\n",
      "Epoch 893: 604 / 1000\n",
      "Epoch 894: 607 / 1000\n",
      "Epoch 895: 599 / 1000\n",
      "Epoch 896: 595 / 1000\n",
      "Epoch 897: 600 / 1000\n",
      "Epoch 898: 606 / 1000\n",
      "Epoch 899: 618 / 1000\n",
      "Epoch 900: 579 / 1000\n",
      "Epoch 901: 595 / 1000\n",
      "Epoch 902: 611 / 1000\n",
      "Epoch 903: 607 / 1000\n",
      "Epoch 904: 604 / 1000\n",
      "Epoch 905: 596 / 1000\n",
      "Epoch 906: 613 / 1000\n",
      "Epoch 907: 600 / 1000\n",
      "Epoch 908: 573 / 1000\n",
      "Epoch 909: 594 / 1000\n",
      "Epoch 910: 612 / 1000\n",
      "Epoch 911: 615 / 1000\n",
      "Epoch 912: 606 / 1000\n",
      "Epoch 913: 600 / 1000\n",
      "Epoch 914: 608 / 1000\n",
      "Epoch 915: 606 / 1000\n",
      "Epoch 916: 605 / 1000\n",
      "Epoch 917: 606 / 1000\n",
      "Epoch 918: 612 / 1000\n",
      "Epoch 919: 605 / 1000\n",
      "Epoch 920: 608 / 1000\n",
      "Epoch 921: 612 / 1000\n",
      "Epoch 922: 588 / 1000\n",
      "Epoch 923: 604 / 1000\n",
      "Epoch 924: 612 / 1000\n",
      "Epoch 925: 598 / 1000\n",
      "Epoch 926: 588 / 1000\n",
      "Epoch 927: 613 / 1000\n",
      "Epoch 928: 609 / 1000\n",
      "Epoch 929: 584 / 1000\n",
      "Epoch 930: 612 / 1000\n",
      "Epoch 931: 605 / 1000\n",
      "Epoch 932: 608 / 1000\n",
      "Epoch 933: 592 / 1000\n",
      "Epoch 934: 596 / 1000\n",
      "Epoch 935: 599 / 1000\n",
      "Epoch 936: 587 / 1000\n",
      "Epoch 937: 603 / 1000\n",
      "Epoch 938: 608 / 1000\n",
      "Epoch 939: 624 / 1000\n",
      "Epoch 940: 594 / 1000\n",
      "Epoch 941: 628 / 1000\n",
      "Epoch 942: 585 / 1000\n",
      "Epoch 943: 575 / 1000\n",
      "Epoch 944: 609 / 1000\n",
      "Epoch 945: 610 / 1000\n",
      "Epoch 946: 614 / 1000\n",
      "Epoch 947: 596 / 1000\n",
      "Epoch 948: 602 / 1000\n",
      "Epoch 949: 587 / 1000\n",
      "Epoch 950: 588 / 1000\n",
      "Epoch 951: 587 / 1000\n",
      "Epoch 952: 611 / 1000\n",
      "Epoch 953: 613 / 1000\n",
      "Epoch 954: 595 / 1000\n",
      "Epoch 955: 573 / 1000\n",
      "Epoch 956: 604 / 1000\n",
      "Epoch 957: 597 / 1000\n",
      "Epoch 958: 590 / 1000\n",
      "Epoch 959: 585 / 1000\n",
      "Epoch 960: 605 / 1000\n",
      "Epoch 961: 598 / 1000\n",
      "Epoch 962: 596 / 1000\n",
      "Epoch 963: 615 / 1000\n",
      "Epoch 964: 596 / 1000\n",
      "Epoch 965: 607 / 1000\n",
      "Epoch 966: 600 / 1000\n",
      "Epoch 967: 605 / 1000\n",
      "Epoch 968: 607 / 1000\n",
      "Epoch 969: 609 / 1000\n",
      "Epoch 970: 607 / 1000\n",
      "Epoch 971: 590 / 1000\n",
      "Epoch 972: 587 / 1000\n",
      "Epoch 973: 603 / 1000\n",
      "Epoch 974: 616 / 1000\n",
      "Epoch 975: 602 / 1000\n",
      "Epoch 976: 599 / 1000\n",
      "Epoch 977: 600 / 1000\n",
      "Epoch 978: 611 / 1000\n",
      "Epoch 979: 610 / 1000\n",
      "Epoch 980: 601 / 1000\n",
      "Epoch 981: 604 / 1000\n",
      "Epoch 982: 594 / 1000\n",
      "Epoch 983: 583 / 1000\n",
      "Epoch 984: 611 / 1000\n",
      "Epoch 985: 594 / 1000\n",
      "Epoch 986: 609 / 1000\n",
      "Epoch 987: 602 / 1000\n",
      "Epoch 988: 602 / 1000\n",
      "Epoch 989: 603 / 1000\n",
      "Epoch 990: 594 / 1000\n",
      "Epoch 991: 592 / 1000\n",
      "Epoch 992: 618 / 1000\n",
      "Epoch 993: 602 / 1000\n",
      "Epoch 994: 607 / 1000\n",
      "Epoch 995: 585 / 1000\n",
      "Epoch 996: 587 / 1000\n",
      "Epoch 997: 614 / 1000\n",
      "Epoch 998: 603 / 1000\n",
      "Epoch 999: 594 / 1000\n",
      "Epoch 1000: 595 / 1000\n",
      "Epoch 1001: 603 / 1000\n",
      "Epoch 1002: 614 / 1000\n",
      "Epoch 1003: 611 / 1000\n",
      "Epoch 1004: 590 / 1000\n",
      "Epoch 1005: 578 / 1000\n",
      "Epoch 1006: 589 / 1000\n",
      "Epoch 1007: 601 / 1000\n",
      "Epoch 1008: 607 / 1000\n",
      "Epoch 1009: 596 / 1000\n",
      "Epoch 1010: 624 / 1000\n",
      "Epoch 1011: 593 / 1000\n",
      "Epoch 1012: 595 / 1000\n",
      "Epoch 1013: 610 / 1000\n",
      "Epoch 1014: 587 / 1000\n",
      "Epoch 1015: 603 / 1000\n",
      "Epoch 1016: 602 / 1000\n",
      "Epoch 1017: 601 / 1000\n",
      "Epoch 1018: 589 / 1000\n",
      "Epoch 1019: 614 / 1000\n",
      "Epoch 1020: 576 / 1000\n",
      "Epoch 1021: 573 / 1000\n",
      "Epoch 1022: 598 / 1000\n",
      "Epoch 1023: 613 / 1000\n",
      "Epoch 1024: 598 / 1000\n",
      "Epoch 1025: 608 / 1000\n",
      "Epoch 1026: 598 / 1000\n",
      "Epoch 1027: 592 / 1000\n",
      "Epoch 1028: 600 / 1000\n",
      "Epoch 1029: 606 / 1000\n",
      "Epoch 1030: 610 / 1000\n",
      "Epoch 1031: 600 / 1000\n",
      "Epoch 1032: 606 / 1000\n",
      "Epoch 1033: 620 / 1000\n",
      "Epoch 1034: 610 / 1000\n",
      "Epoch 1035: 602 / 1000\n",
      "Epoch 1036: 606 / 1000\n",
      "Epoch 1037: 618 / 1000\n",
      "Epoch 1038: 594 / 1000\n",
      "Epoch 1039: 607 / 1000\n",
      "Epoch 1040: 599 / 1000\n",
      "Epoch 1041: 591 / 1000\n",
      "Epoch 1042: 597 / 1000\n",
      "Epoch 1043: 609 / 1000\n",
      "Epoch 1044: 594 / 1000\n",
      "Epoch 1045: 597 / 1000\n",
      "Epoch 1046: 608 / 1000\n",
      "Epoch 1047: 605 / 1000\n",
      "Epoch 1048: 605 / 1000\n",
      "Epoch 1049: 616 / 1000\n",
      "Epoch 1050: 602 / 1000\n",
      "Epoch 1051: 600 / 1000\n",
      "Epoch 1052: 600 / 1000\n",
      "Epoch 1053: 601 / 1000\n",
      "Epoch 1054: 590 / 1000\n",
      "Epoch 1055: 609 / 1000\n",
      "Epoch 1056: 578 / 1000\n",
      "Epoch 1057: 615 / 1000\n",
      "Epoch 1058: 613 / 1000\n",
      "Epoch 1059: 610 / 1000\n",
      "Epoch 1060: 614 / 1000\n",
      "Epoch 1061: 581 / 1000\n",
      "Epoch 1062: 598 / 1000\n",
      "Epoch 1063: 608 / 1000\n",
      "Epoch 1064: 602 / 1000\n",
      "Epoch 1065: 596 / 1000\n",
      "Epoch 1066: 602 / 1000\n",
      "Epoch 1067: 611 / 1000\n",
      "Epoch 1068: 607 / 1000\n",
      "Epoch 1069: 619 / 1000\n",
      "Epoch 1070: 606 / 1000\n",
      "Epoch 1071: 607 / 1000\n",
      "Epoch 1072: 585 / 1000\n",
      "Epoch 1073: 599 / 1000\n",
      "Epoch 1074: 604 / 1000\n",
      "Epoch 1075: 599 / 1000\n",
      "Epoch 1076: 581 / 1000\n",
      "Epoch 1077: 584 / 1000\n",
      "Epoch 1078: 599 / 1000\n",
      "Epoch 1079: 595 / 1000\n",
      "Epoch 1080: 581 / 1000\n",
      "Epoch 1081: 611 / 1000\n",
      "Epoch 1082: 604 / 1000\n",
      "Epoch 1083: 615 / 1000\n",
      "Epoch 1084: 577 / 1000\n",
      "Epoch 1085: 607 / 1000\n",
      "Epoch 1086: 621 / 1000\n",
      "Epoch 1087: 562 / 1000\n",
      "Epoch 1088: 588 / 1000\n",
      "Epoch 1089: 609 / 1000\n",
      "Epoch 1090: 587 / 1000\n",
      "Epoch 1091: 618 / 1000\n",
      "Epoch 1092: 591 / 1000\n",
      "Epoch 1093: 598 / 1000\n",
      "Epoch 1094: 591 / 1000\n",
      "Epoch 1095: 591 / 1000\n",
      "Epoch 1096: 595 / 1000\n",
      "Epoch 1097: 620 / 1000\n",
      "Epoch 1098: 580 / 1000\n",
      "Epoch 1099: 594 / 1000\n",
      "Epoch 1100: 587 / 1000\n",
      "Epoch 1101: 608 / 1000\n",
      "Epoch 1102: 585 / 1000\n",
      "Epoch 1103: 609 / 1000\n",
      "Epoch 1104: 606 / 1000\n",
      "Epoch 1105: 604 / 1000\n",
      "Epoch 1106: 591 / 1000\n",
      "Epoch 1107: 607 / 1000\n",
      "Epoch 1108: 599 / 1000\n",
      "Epoch 1109: 609 / 1000\n",
      "Epoch 1110: 602 / 1000\n",
      "Epoch 1111: 617 / 1000\n",
      "Epoch 1112: 604 / 1000\n",
      "Epoch 1113: 607 / 1000\n",
      "Epoch 1114: 596 / 1000\n",
      "Epoch 1115: 606 / 1000\n",
      "Epoch 1116: 571 / 1000\n",
      "Epoch 1117: 607 / 1000\n",
      "Epoch 1118: 590 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1119: 602 / 1000\n",
      "Epoch 1120: 596 / 1000\n",
      "Epoch 1121: 587 / 1000\n",
      "Epoch 1122: 608 / 1000\n",
      "Epoch 1123: 602 / 1000\n",
      "Epoch 1124: 593 / 1000\n",
      "Epoch 1125: 595 / 1000\n",
      "Epoch 1126: 588 / 1000\n",
      "Epoch 1127: 605 / 1000\n",
      "Epoch 1128: 609 / 1000\n",
      "Epoch 1129: 604 / 1000\n",
      "Epoch 1130: 576 / 1000\n",
      "Epoch 1131: 605 / 1000\n",
      "Epoch 1132: 619 / 1000\n",
      "Epoch 1133: 616 / 1000\n",
      "Epoch 1134: 582 / 1000\n",
      "Epoch 1135: 609 / 1000\n",
      "Epoch 1136: 597 / 1000\n",
      "Epoch 1137: 583 / 1000\n",
      "Epoch 1138: 610 / 1000\n",
      "Epoch 1139: 597 / 1000\n",
      "Epoch 1140: 603 / 1000\n",
      "Epoch 1141: 602 / 1000\n",
      "Epoch 1142: 569 / 1000\n",
      "Epoch 1143: 602 / 1000\n",
      "Epoch 1144: 611 / 1000\n",
      "Epoch 1145: 600 / 1000\n",
      "Epoch 1146: 591 / 1000\n",
      "Epoch 1147: 595 / 1000\n",
      "Epoch 1148: 593 / 1000\n",
      "Epoch 1149: 597 / 1000\n",
      "Epoch 1150: 587 / 1000\n",
      "Epoch 1151: 607 / 1000\n",
      "Epoch 1152: 610 / 1000\n",
      "Epoch 1153: 582 / 1000\n",
      "Epoch 1154: 600 / 1000\n",
      "Epoch 1155: 583 / 1000\n",
      "Epoch 1156: 603 / 1000\n",
      "Epoch 1157: 591 / 1000\n",
      "Epoch 1158: 606 / 1000\n",
      "Epoch 1159: 616 / 1000\n",
      "Epoch 1160: 603 / 1000\n",
      "Epoch 1161: 591 / 1000\n",
      "Epoch 1162: 579 / 1000\n",
      "Epoch 1163: 605 / 1000\n",
      "Epoch 1164: 564 / 1000\n",
      "Epoch 1165: 604 / 1000\n",
      "Epoch 1166: 611 / 1000\n",
      "Epoch 1167: 606 / 1000\n",
      "Epoch 1168: 617 / 1000\n",
      "Epoch 1169: 575 / 1000\n",
      "Epoch 1170: 596 / 1000\n",
      "Epoch 1171: 606 / 1000\n",
      "Epoch 1172: 609 / 1000\n",
      "Epoch 1173: 584 / 1000\n",
      "Epoch 1174: 603 / 1000\n",
      "Epoch 1175: 595 / 1000\n",
      "Epoch 1176: 600 / 1000\n",
      "Epoch 1177: 602 / 1000\n",
      "Epoch 1178: 605 / 1000\n",
      "Epoch 1179: 628 / 1000\n",
      "Epoch 1180: 600 / 1000\n",
      "Epoch 1181: 594 / 1000\n",
      "Epoch 1182: 601 / 1000\n",
      "Epoch 1183: 586 / 1000\n",
      "Epoch 1184: 596 / 1000\n",
      "Epoch 1185: 595 / 1000\n",
      "Epoch 1186: 587 / 1000\n",
      "Epoch 1187: 597 / 1000\n",
      "Epoch 1188: 599 / 1000\n",
      "Epoch 1189: 600 / 1000\n",
      "Epoch 1190: 592 / 1000\n",
      "Epoch 1191: 591 / 1000\n",
      "Epoch 1192: 593 / 1000\n",
      "Epoch 1193: 586 / 1000\n",
      "Epoch 1194: 612 / 1000\n",
      "Epoch 1195: 571 / 1000\n",
      "Epoch 1196: 595 / 1000\n",
      "Epoch 1197: 591 / 1000\n",
      "Epoch 1198: 598 / 1000\n",
      "Epoch 1199: 599 / 1000\n",
      "Epoch 1200: 606 / 1000\n",
      "Epoch 1201: 603 / 1000\n",
      "Epoch 1202: 598 / 1000\n",
      "Epoch 1203: 566 / 1000\n",
      "Epoch 1204: 596 / 1000\n",
      "Epoch 1205: 592 / 1000\n",
      "Epoch 1206: 595 / 1000\n",
      "Epoch 1207: 605 / 1000\n",
      "Epoch 1208: 596 / 1000\n",
      "Epoch 1209: 598 / 1000\n",
      "Epoch 1210: 599 / 1000\n",
      "Epoch 1211: 614 / 1000\n",
      "Epoch 1212: 577 / 1000\n",
      "Epoch 1213: 596 / 1000\n",
      "Epoch 1214: 610 / 1000\n",
      "Epoch 1215: 589 / 1000\n",
      "Epoch 1216: 579 / 1000\n",
      "Epoch 1217: 605 / 1000\n",
      "Epoch 1218: 604 / 1000\n",
      "Epoch 1219: 592 / 1000\n",
      "Epoch 1220: 597 / 1000\n",
      "Epoch 1221: 580 / 1000\n",
      "Epoch 1222: 600 / 1000\n",
      "Epoch 1223: 604 / 1000\n",
      "Epoch 1224: 591 / 1000\n",
      "Epoch 1225: 609 / 1000\n",
      "Epoch 1226: 585 / 1000\n",
      "Epoch 1227: 583 / 1000\n",
      "Epoch 1228: 605 / 1000\n",
      "Epoch 1229: 592 / 1000\n",
      "Epoch 1230: 559 / 1000\n",
      "Epoch 1231: 590 / 1000\n",
      "Epoch 1232: 574 / 1000\n",
      "Epoch 1233: 602 / 1000\n",
      "Epoch 1234: 606 / 1000\n",
      "Epoch 1235: 589 / 1000\n",
      "Epoch 1236: 609 / 1000\n",
      "Epoch 1237: 596 / 1000\n",
      "Epoch 1238: 593 / 1000\n",
      "Epoch 1239: 598 / 1000\n",
      "Epoch 1240: 580 / 1000\n",
      "Epoch 1241: 597 / 1000\n",
      "Epoch 1242: 609 / 1000\n",
      "Epoch 1243: 601 / 1000\n",
      "Epoch 1244: 597 / 1000\n",
      "Epoch 1245: 583 / 1000\n",
      "Epoch 1246: 586 / 1000\n",
      "Epoch 1247: 591 / 1000\n",
      "Epoch 1248: 599 / 1000\n",
      "Epoch 1249: 587 / 1000\n",
      "Epoch 1250: 618 / 1000\n",
      "Epoch 1251: 611 / 1000\n",
      "Epoch 1252: 598 / 1000\n",
      "Epoch 1253: 573 / 1000\n",
      "Epoch 1254: 608 / 1000\n",
      "Epoch 1255: 587 / 1000\n",
      "Epoch 1256: 604 / 1000\n",
      "Epoch 1257: 592 / 1000\n",
      "Epoch 1258: 605 / 1000\n",
      "Epoch 1259: 610 / 1000\n",
      "Epoch 1260: 611 / 1000\n",
      "Epoch 1261: 616 / 1000\n",
      "Epoch 1262: 603 / 1000\n",
      "Epoch 1263: 603 / 1000\n",
      "Epoch 1264: 602 / 1000\n",
      "Epoch 1265: 596 / 1000\n",
      "Epoch 1266: 585 / 1000\n",
      "Epoch 1267: 599 / 1000\n",
      "Epoch 1268: 598 / 1000\n",
      "Epoch 1269: 592 / 1000\n",
      "Epoch 1270: 588 / 1000\n",
      "Epoch 1271: 604 / 1000\n",
      "Epoch 1272: 588 / 1000\n",
      "Epoch 1273: 601 / 1000\n",
      "Epoch 1274: 605 / 1000\n",
      "Epoch 1275: 599 / 1000\n",
      "Epoch 1276: 596 / 1000\n",
      "Epoch 1277: 601 / 1000\n",
      "Epoch 1278: 596 / 1000\n",
      "Epoch 1279: 607 / 1000\n",
      "Epoch 1280: 608 / 1000\n",
      "Epoch 1281: 598 / 1000\n",
      "Epoch 1282: 597 / 1000\n",
      "Epoch 1283: 618 / 1000\n",
      "Epoch 1284: 601 / 1000\n",
      "Epoch 1285: 595 / 1000\n",
      "Epoch 1286: 598 / 1000\n",
      "Epoch 1287: 616 / 1000\n",
      "Epoch 1288: 589 / 1000\n",
      "Epoch 1289: 602 / 1000\n",
      "Epoch 1290: 598 / 1000\n",
      "Epoch 1291: 598 / 1000\n",
      "Epoch 1292: 592 / 1000\n",
      "Epoch 1293: 584 / 1000\n",
      "Epoch 1294: 595 / 1000\n",
      "Epoch 1295: 601 / 1000\n",
      "Epoch 1296: 606 / 1000\n",
      "Epoch 1297: 590 / 1000\n",
      "Epoch 1298: 582 / 1000\n",
      "Epoch 1299: 592 / 1000\n",
      "Epoch 1300: 597 / 1000\n",
      "Epoch 1301: 603 / 1000\n",
      "Epoch 1302: 598 / 1000\n",
      "Epoch 1303: 614 / 1000\n",
      "Epoch 1304: 614 / 1000\n",
      "Epoch 1305: 608 / 1000\n",
      "Epoch 1306: 585 / 1000\n",
      "Epoch 1307: 605 / 1000\n",
      "Epoch 1308: 585 / 1000\n",
      "Epoch 1309: 593 / 1000\n",
      "Epoch 1310: 594 / 1000\n",
      "Epoch 1311: 596 / 1000\n",
      "Epoch 1312: 601 / 1000\n",
      "Epoch 1313: 594 / 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6534b51aaffe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.03\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musing_soft_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musing_adam_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-82ba881af89b>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, test_data, using_soft_max, using_adam_optimizer)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmini_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmini_batches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musing_soft_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0musing_soft_max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musing_adam_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0musing_adam_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch {0}: {1} / {2}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musing_soft_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-82ba881af89b>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[1;34m(self, mini_batch, eta, epoch, using_soft_max, using_adam_optimizer)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mnabla_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mdelta_nabla_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoft_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mnabla_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdnb\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnabla_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_nabla_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mnabla_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdnw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnabla_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-82ba881af89b>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, x, y, using_soft_max)\u001b[0m\n\u001b[0;32m    102\u001b[0m         to ``self.biases`` and ``self.weights``.\"\"\"\n\u001b[0;32m    103\u001b[0m         \u001b[0mnabla_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mnabla_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;31m# feedforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-82ba881af89b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    102\u001b[0m         to ``self.biases`` and ``self.weights``.\"\"\"\n\u001b[0;32m    103\u001b[0m         \u001b[0mnabla_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mnabla_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;31m# feedforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ann.SGD(learning_dataset,2000,32,0.03,test_data=evaluation_dataset, using_soft_max=True,using_adam_optimizer=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
