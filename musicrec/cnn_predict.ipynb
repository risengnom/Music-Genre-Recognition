{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import numpy, scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "duration = 2.97\n",
    "sr = 22050 # if sampling rate is different, resample it to this\n",
    "input_root = './../../../models/'\n",
    "input_whole = input_root + 'cnn_dong_model_whole.h5'\n",
    "input_label = input_root + 'label.pkl'\n",
    "input_test_paths = input_root + 'test_paths.pkl'\n",
    "default_song = Path(\"../../../audio/testfiles/GTZAN/genres/rock/rock.00003.wav\")\n",
    "output_test_results = input_root + 'predictions_cnn.pkl'\n",
    "output_test_results_csv = input_root + 'predictions_cnn.csv'\n",
    "fmax = 1500 # maximum frequency considered\n",
    "fft_window_points = 512\n",
    "fft_window_dur = fft_window_points * 1.0 / sr # 23ms windows\n",
    "hop_size = int(fft_window_points/ 2) # 50% overlap between consecutive frames\n",
    "n_mels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model, labels and paths for songs to predict\n",
    "model = load_model(input_whole)\n",
    "with open(input_label, 'rb') as f:\n",
    "    lb = pickle.load(f)\n",
    "with open(input_test_paths, 'rb') as f:\n",
    "    paths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song(song = default_song, offset = 0):\n",
    "    offset = duration*offset\n",
    "    y, sr = librosa.load(song, mono=True, offset=offset, duration=duration)\n",
    "    m_sp = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=fft_window_points,\n",
    "                                              hop_length=hop_size, n_mels=n_mels,\n",
    "                                              fmax=fmax)\n",
    "    #plt.figure(figsize=(15, 5))\n",
    "    #librosa.display.specshow(m_sp, sr=sr, hop_length=hop_size, x_axis='time', y_axis='mel')\n",
    "    #plt.colorbar(format='%+2.0f dB')\n",
    "    m_sp = np.expand_dims(m_sp, 0)\n",
    "    m_sp = np.expand_dims(m_sp, 3)\n",
    "    return m_sp\n",
    "        \n",
    "def get_songs_num_offsets(song = default_song, num = 1):\n",
    "    samples = []\n",
    "    for i  in range(num):\n",
    "        samples.append(load_song(song = song, offset =  i))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_song(song = default_song, number_of_offsets = 1):\n",
    "    samples = get_songs_num_offsets(song = song, num = number_of_offsets)\n",
    "    p = 0\n",
    "    pr_n = []\n",
    "    for sample in samples:\n",
    "        prediction = model.predict(sample)\n",
    "        if p == 0:\n",
    "            pr_n = prediction\n",
    "            p = 1\n",
    "        else:\n",
    "            pr_n = pr_n + prediction / 2\n",
    "    #print(pr_n)\n",
    "    #print(lb.classes_[pr_n.argmax(axis=-1)])\n",
    "    return pr_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename',\n",
       " 'chroma_stft',\n",
       " 'spectral_centroid',\n",
       " 'spectral_bandwidth',\n",
       " 'rolloff',\n",
       " 'zero_crossing_rate',\n",
       " 'mfcc1',\n",
       " 'mfcc2',\n",
       " 'mfcc3',\n",
       " 'mfcc4',\n",
       " 'mfcc5',\n",
       " 'mfcc6',\n",
       " 'mfcc7',\n",
       " 'mfcc8',\n",
       " 'mfcc9',\n",
       " 'mfcc10',\n",
       " 'mfcc11',\n",
       " 'mfcc12',\n",
       " 'mfcc13',\n",
       " 'mfcc14',\n",
       " 'mfcc15',\n",
       " 'mfcc16',\n",
       " 'mfcc17',\n",
       " 'mfcc18',\n",
       " 'mfcc19',\n",
       " 'mfcc20',\n",
       " 'pred.blues',\n",
       " 'pred.classical',\n",
       " 'pred.country',\n",
       " 'pred.disco',\n",
       " 'pred.hiphop',\n",
       " 'pred.jazz',\n",
       " 'pred.metal',\n",
       " 'pred.pop',\n",
       " 'pred.reggae',\n",
       " 'pred.rock',\n",
       " 'pred.argmax']"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = 'filename chroma_stft spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += f' pred.blues pred.classical pred.country pred.disco pred.hiphop pred.jazz pred.metal pred.pop pred.reggae pred.rock pred.argmax'\n",
    "header = header.split()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_songs = []\n",
    "file = open(output_test_results_csv, 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for path in paths:\n",
    "    prediction = predict_song(song = path, number_of_offsets = 1)[0]\n",
    "    prediciton = np.reshape(prediction, (10,1))\n",
    "    y, sr = librosa.load(path, mono=True, duration=30)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    #rmse = librosa.feature.rmse(y=y, S=None, frame_length=2048, hop_length=512, center=True, pad_mode='reflect')\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    to_append = f'{path.name} {np.mean(chroma_stft)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    for e in prediction:\n",
    "        to_append += f' {e}'\n",
    "    #to_append += f' {re.sub('[\\[\\]\\']', '', str(lb.classes_[prediction.argmax(axis=-1)]))}'\n",
    "    to_append += f' {str(lb.classes_[prediction.argmax(axis=-1)])}'\n",
    "    arr = (to_append.split())\n",
    "    file = open(output_test_results_csv, 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(arr)\n",
    "    p_songs.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_test_results, 'wb') as f:\n",
    "    pickle.dump(p_songs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p_songs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicrec2",
   "language": "python",
   "name": "musicrec2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
