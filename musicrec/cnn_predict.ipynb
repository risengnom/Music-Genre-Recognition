{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import csv\n",
    "import progress\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "duration = 2.97\n",
    "sr = 22050 # sampling rate\n",
    "input_root = './../../../models/'\n",
    "input_whole = input_root + 'cnn_dong_model_65pct.h5'\n",
    "input_label = input_root + 'label.pkl'\n",
    "input_test_paths = input_root + 'test_paths.pkl'\n",
    "default_song = Path(\"../../../audio/testfiles/GTZAN/genres/rock/rock.00003.wav\")\n",
    "output_test_results = input_root + 'predictions_cnn.pkl'\n",
    "output_test_results_csv = input_root + 'predictions_cnn.csv'\n",
    "fmax = 1500 # maximum frequency considered\n",
    "fft_points = 512\n",
    "hop_size = int(fft_points/ 2) # 50% overlap between consecutive frames\n",
    "n_mels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Initializing Prediction. Loading model: ./../../../models/cnn_dong_model_whole.h5\n",
      "WARNING:tensorflow:From /home/carsten/.local/share/virtualenvs/is_music-genre-recognition-7WxnqNEu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/carsten/.local/share/virtualenvs/is_music-genre-recognition-7WxnqNEu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/carsten/.local/share/virtualenvs/is_music-genre-recognition-7WxnqNEu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[INFO]: Done loading model.\n",
      "[INFO]: Loading song specifications: ./../../../models/test_paths.pkl\n",
      "[INFO]: Done loading song specifications.\n"
     ]
    }
   ],
   "source": [
    "#load model, labels and paths for songs to predict\n",
    "print(\"[INFO]: Initializing Prediction. Loading model: \" + str(input_whole))\n",
    "model = load_model(input_whole)\n",
    "with open(input_label, 'rb') as f:\n",
    "    lb = pickle.load(f)\n",
    "print(\"[INFO]: Done loading model.\")\n",
    "\n",
    "print(\"[INFO]: Loading song specifications: \" + str(input_test_paths))\n",
    "with open(input_test_paths, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "print(\"[INFO]: Done loading song specifications.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Ingested dimensions are fine! Amount of Datapoints: 4000\n"
     ]
    }
   ],
   "source": [
    "paths = data[0]\n",
    "offsets = data [1]\n",
    "durations = data [2]\n",
    "if len(paths) == len(offsets) and len(offsets) == len(durations):\n",
    "    print(\"[INFO]: Ingested dimensions are fine! Amount of Datapoints: \" + str(len(paths)))\n",
    "else:\n",
    "    print(\"[Error]: Dimensions of read file invalid!\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Writing .csv to following location: ./../../../models/predictions_cnn.csv\n"
     ]
    }
   ],
   "source": [
    "#create header\n",
    "print(\"[INFO]: Writing .csv to following location: \" + str(output_test_results_csv))\n",
    "header = 'filename offset duration chroma_stft spectral_centroid spectral_bandwidth rolloff zero_crossing_rate tempo'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += f' blues classical country disco hiphop jazz metal pop reggae rock'\n",
    "header = header.split()\n",
    "#write header to .csv\n",
    "file = open(output_test_results_csv, 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress.startProgress(\"[INFO]: Calculating and saving features and CVN prediction for \" + str(len(paths)) + \" samples...\")\n",
    "p_songs = []\n",
    "i = 0\n",
    "\n",
    "for path in paths:\n",
    "    y, sr = librosa.load(path, mono=True, offset=offsets[i], duration=durations[i])\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    #rmse = librosa.feature.rmse(y=y, S=None, frame_length=2048, hop_length=512, center=True, pad_mode='reflect')\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    onset_env = librosa.onset.onset_strength(y, sr=sr) #added\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr) #added\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    m_sp = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=fft_points,\n",
    "                                              hop_length=hop_size, n_mels=n_mels,\n",
    "                                              fmax=fmax)\n",
    "    m_sp = np.expand_dims(m_sp, 0)\n",
    "    m_sp = np.expand_dims(m_sp, 3)\n",
    "    cvn_prediction = model.predict(m_sp)\n",
    "    to_append = f'{path.name} {offsets[i]} {durations[i]} {np.mean(chroma_stft)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)} {np.mean(tempo)}'    \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    for e in cvn_prediction:\n",
    "        e = re.sub('[\\[\\]]', '', str(e))\n",
    "        to_append += f' {e}'\n",
    "    #to_append += f' {str(lb.classes_[prediction.argmax(axis=-1)])}'\n",
    "    arr = (to_append.split())\n",
    "    file = open(output_test_results_csv, 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(arr)\n",
    "    p_songs.append(arr)\n",
    "    i = i+1\n",
    "    progress.progress((i/len(paths))*100)\n",
    "progress.endProgress()\n",
    "print(\"[INFO]: Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_test_results, 'wb') as f:\n",
    "    pickle.dump(p_songs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicrec2",
   "language": "python",
   "name": "musicrec2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
