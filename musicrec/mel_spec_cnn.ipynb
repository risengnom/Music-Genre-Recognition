{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")\n",
    "%matplotlib inline\n",
    "\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plot\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import argmax\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "\n",
    "#Visualization\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "#env parameters\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramters\n",
    "data_folder = Path(\"../../../audio/testfiles/GTZAN_test/genres/\")\n",
    "output_root = './../../../models/'\n",
    "output_folder = Path('./output/cvnn.model')\n",
    "output_model = output_root + '/cnn_dong_model_weights.h5'\n",
    "output_architecture = output_root + '/cnn_dong_model_architecture.json'\n",
    "output_whole = output_root + 'cnn_dong_model_whole.h5'\n",
    "output_best_model = output_root + 'best_model.h5'\n",
    "output_label = output_root + 'label.pkl'\n",
    "output_test_paths = output_root + 'test_paths.pkl'\n",
    "spectogram_folder = Path(\"./img_data/\")\n",
    "# Duration of songsnippet in seconds\n",
    "duration = 2.97\n",
    "start_offset = 0\n",
    "epochs = 4\n",
    "num_segments = 1\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "es_patience = 20\n",
    "return_train_and_test = 1\n",
    "\n",
    "sr = 22050 # Sampling rate\n",
    "\n",
    "#Parameters for mel spec\n",
    "fmax = 1500 # maximum frequency considered\n",
    "fft_points = 512\n",
    "fft_dur = fft_points * 1.0 / sr # 23ms windows\n",
    "hop_size = int(fft_points/ 2) # 50% overlap between consecutive frames\n",
    "n_mels = 64\n",
    "\n",
    "#Segment duration\n",
    "num_fft_windows = 256 #per Segment\n",
    "segment_in_points = num_fft_windows * 255\n",
    "segment_dur = segment_in_points * 1.0 / sr\n",
    "\n",
    "input_shape=(64, 256, 1)\n",
    "\n",
    "randomseed = 11\n",
    "#randomseed = datetime.now()\n",
    "# Seed for RNG\n",
    "random.seed(randomseed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get directories of all songs\n",
    "songs = []\n",
    "genres = []\n",
    "\n",
    "for g in data_folder.iterdir():\n",
    "    genres.append(g.name)\n",
    "    for i in g.iterdir():\n",
    "        songs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_specs = []  \n",
    "labels = []\n",
    "\n",
    "#loading with different numbers of segements for data-augmentation\n",
    "#!Initialize \"spectograms\" before running\n",
    "def load_specs(data = songs, num_segments = 1):\n",
    "    spectograms = []\n",
    "    for song in data:\n",
    "        offset = start_offset\n",
    "        for i in range(num_segments):\n",
    "            y, sr = librosa.load(song, mono=True, offset=offset, duration=duration)\n",
    "            m_sp = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=fft_points,\n",
    "                                                  hop_length=hop_size, n_mels=n_mels,\n",
    "                                                  fmax=fmax)\n",
    "            mel_specs.append([m_sp])\n",
    "            label = song.parts[-2]\n",
    "            labels.append(label)\n",
    "            spectograms.append( (m_sp, label, song, offset, duration) )\n",
    "            offset = offset + duration/2\n",
    "        input_shape = m_sp.shape + (1,)\n",
    "    return spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle songs to keep segements together\n",
    "random.shuffle(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectograms = load_specs(data = songs, num_segments = num_segments)\n",
    "len(spectograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples:  60\n",
      "Input shape: (64, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of samples: \", len(mel_specs))\n",
    "\n",
    "#set dynamic input shape\n",
    "input_shape = np.shape(mel_specs[2]) + (1,)\n",
    "input_shape = (input_shape[1], input_shape[2], input_shape[3])\n",
    "print(\"Input shape: \" + str(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Train and Testing\n",
    "testsplit = len(spectograms)*0.7    #70% train-test-split\n",
    "train = spectograms[:int(testsplit)]\n",
    "test = spectograms[int(testsplit):]\n",
    "\n",
    "x_train, y_train, p_train, offset_train, duration_train = zip(*train)\n",
    "x_test, y_test, p_test, offset_test, duration_test = zip(*test)\n",
    "\n",
    "#Fit Dimensions\n",
    "x_train = np.array([x.reshape(input_shape) for x in x_train])\n",
    "x_test = np.array([x.reshape(input_shape) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarize Labels\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_testspecs_labels():\n",
    "    with open(output_label, 'wb') as f:\n",
    "        pickle.dump(lb, f)\n",
    "\n",
    "    if return_train_and_test == 1:\n",
    "        r_paths = p_test + (p_train)\n",
    "        r_offsets = offset_test + (offset_train)\n",
    "        r_durations = duration_test + (duration_train)\n",
    "    else:\n",
    "        r_paths = p_test\n",
    "        r_offsets = offset_test\n",
    "        r_durations = duration_test\n",
    "\n",
    "    r_values = [r_paths, r_offsets, r_durations]\n",
    "\n",
    "    with open(output_test_paths, 'wb') as f:\n",
    "        pickle.dump(r_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump_testspecs_labels():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old model for urban\n",
    "def cnn_urban_model_build():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "    model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=['accuracy'])\n",
    "    print(model.summary)\n",
    "    return model\n",
    "\n",
    "#model for GTZAN\n",
    "def cnn_dong_model_build():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                     activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 4)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 5), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 4)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(len(genres), activation='softmax'))\n",
    "    #model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "     #             optimizer=keras.optimizers.Adadelta(decay=1e-6),\n",
    "      #            metrics=['accuracy'])\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=['accuracy'])\n",
    "    print(model.summary)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model = cnn_dong_model_build()\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=es_patience),\n",
    "                 ModelCheckpoint(filepath=output_best_model, monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "    H = model.fit(\n",
    "        x=x_train, \n",
    "        y=y_train,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        batch_size=batch_size,\n",
    "        validation_data= (x_test, y_test))\n",
    "\n",
    "    score = model.evaluate(x=x_test,y=y_test)\n",
    "\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    # Save the weights\n",
    "    model.save_weights(output_model)\n",
    "\n",
    "    # Save the model architecture\n",
    "    with open(output_architecture, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "    # Save complete model\n",
    "    model.save(output_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f27a8460e80>>\n",
      "Train on 42 samples, validate on 18 samples\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 2s 43ms/step - loss: 5.5693 - acc: 0.0952 - val_loss: 7.7844 - val_acc: 0.1111\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 5.8243 - acc: 0.1905 - val_loss: 5.3501 - val_acc: 0.1667\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 4.4031 - acc: 0.3333 - val_loss: 4.5545 - val_acc: 0.1111\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 4.2717 - acc: 0.2381 - val_loss: 4.1640 - val_acc: 0.1111\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Test loss: 4.163966178894043\n",
      "Test accuracy: 0.1111111119389534\n"
     ]
    }
   ],
   "source": [
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_song(song):\n",
    "    start = 0\n",
    "    r = 0\n",
    "    for i in range(int(30/(duration/2))-1):\n",
    "        y, sr = librosa.load(song, mono=True, offset=start, duration=duration)\n",
    "        m_sp = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=fft_points,\n",
    "                                              hop_length=hop_size, n_mels=n_mels,\n",
    "                                              fmax=fmax)\n",
    "        m_sp = np.expand_dims(m_sp, 0)\n",
    "        m_sp = np.expand_dims(m_sp, 3)\n",
    "        if r == 0:\n",
    "            prediction = model.predict(m_sp)\n",
    "            r = 1\n",
    "        else:\n",
    "            prediction = (prediction + model.predict(m_sp))/2\n",
    "        start = start + duration/2\n",
    "    return prediction\n",
    "        \n",
    "def evaluate_batch(batch):\n",
    "    predictions = []\n",
    "    for song in batch:\n",
    "        predictions.append(evaluate_song(song))\n",
    "    return predictions\n",
    "\n",
    "def compare_batch(predictions):\n",
    "    i = 0\n",
    "    l = lb.inverse_transform(y_test)\n",
    "    counter = 0\n",
    "    for prediction in predictions:\n",
    "        tr_value = str(l[i])\n",
    "        pr_value = re.sub('[\\[\\]\\']', '', str(lb.classes_[prediction.argmax(axis=1)]))\n",
    "        print(tr_value + \"=>\" + pr_value)\n",
    "        if tr_value == pr_value:\n",
    "            counter += 1\n",
    "        i += 1\n",
    "    acc = counter/len(predictions)*100\n",
    "    print(\"Acc: \" + str(acc) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(output_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.10733238, 0.05372522, 0.15000305, 0.05761873, 0.10228785,\n",
      "        0.16732156, 0.09410034, 0.12233038, 0.07740969, 0.06787084]],\n",
      "      dtype=float32), array([[0.11593819, 0.02786388, 0.11218724, 0.042406  , 0.10997602,\n",
      "        0.2286258 , 0.08105122, 0.13740441, 0.06754923, 0.07699804]],\n",
      "      dtype=float32), array([[3.6127508e-01, 3.7802660e-05, 6.3936867e-02, 1.6394507e-03,\n",
      "        1.0107747e-02, 3.2318134e-02, 6.1927749e-05, 1.5011637e-02,\n",
      "        3.0346238e-03, 5.1257670e-01]], dtype=float32), array([[0.08470407, 0.0197611 , 0.17953536, 0.03227285, 0.22265741,\n",
      "        0.24924105, 0.05443884, 0.08135629, 0.04281237, 0.0332206 ]],\n",
      "      dtype=float32), array([[0.07939922, 0.04697099, 0.14452475, 0.0547954 , 0.13107175,\n",
      "        0.20238805, 0.0879993 , 0.1391128 , 0.05598417, 0.05775359]],\n",
      "      dtype=float32), array([[0.11105043, 0.08569268, 0.10562597, 0.09016043, 0.0910494 ,\n",
      "        0.11209818, 0.0867638 , 0.10922344, 0.09975161, 0.10858406]],\n",
      "      dtype=float32), array([[0.09975287, 0.08722091, 0.10580561, 0.09369662, 0.10050033,\n",
      "        0.11398869, 0.09946483, 0.11015375, 0.09508312, 0.09433325]],\n",
      "      dtype=float32), array([[0.064093  , 0.01386173, 0.13649243, 0.02036208, 0.07896405,\n",
      "        0.3067264 , 0.05496284, 0.25633752, 0.03108215, 0.03711776]],\n",
      "      dtype=float32), array([[0.101515  , 0.03214626, 0.14344513, 0.03588596, 0.12686624,\n",
      "        0.18587339, 0.11463226, 0.1389778 , 0.06459534, 0.05606266]],\n",
      "      dtype=float32), array([[0.07165313, 0.00958967, 0.12310331, 0.01502115, 0.04545981,\n",
      "        0.49814624, 0.02134939, 0.17073482, 0.0320949 , 0.01284762]],\n",
      "      dtype=float32), array([[0.10168499, 0.09537826, 0.09903412, 0.10042463, 0.09820992,\n",
      "        0.10471176, 0.09237906, 0.10343832, 0.1020847 , 0.10265423]],\n",
      "      dtype=float32), array([[0.25178877, 0.00792778, 0.1756261 , 0.01882619, 0.21572518,\n",
      "        0.10746866, 0.06364722, 0.04699713, 0.09935297, 0.01263998]],\n",
      "      dtype=float32), array([[0.10135732, 0.09830587, 0.10167189, 0.09937936, 0.09857166,\n",
      "        0.10099183, 0.09819777, 0.10060653, 0.09982443, 0.10109335]],\n",
      "      dtype=float32), array([[0.09979229, 0.06092478, 0.12830827, 0.06659123, 0.09766035,\n",
      "        0.14995575, 0.0945259 , 0.13986672, 0.07715202, 0.08522269]],\n",
      "      dtype=float32), array([[0.11679907, 0.02662941, 0.08660597, 0.07467309, 0.06542104,\n",
      "        0.21712646, 0.04497699, 0.1838534 , 0.08153304, 0.10238151]],\n",
      "      dtype=float32), array([[0.10511732, 0.09473264, 0.10030665, 0.09562762, 0.09693113,\n",
      "        0.10628282, 0.09367427, 0.10454562, 0.10201221, 0.10076974]],\n",
      "      dtype=float32), array([[0.06443041, 0.00500737, 0.22775152, 0.01043736, 0.23880687,\n",
      "        0.25048482, 0.05617823, 0.12546122, 0.01634592, 0.00509627]],\n",
      "      dtype=float32), array([[0.10109858, 0.09668048, 0.10144062, 0.09871444, 0.09835991,\n",
      "        0.10366634, 0.09712885, 0.10180298, 0.10041037, 0.10069741]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "predictions = evaluate_batch(p_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metal=>jazz\n",
      "disco=>jazz\n",
      "hiphop=>rock\n",
      "pop=>jazz\n",
      "pop=>jazz\n",
      "classical=>jazz\n",
      "metal=>jazz\n",
      "disco=>jazz\n",
      "country=>jazz\n",
      "pop=>jazz\n",
      "classical=>jazz\n",
      "hiphop=>blues\n",
      "jazz=>country\n",
      "metal=>jazz\n",
      "hiphop=>jazz\n",
      "classical=>jazz\n",
      "hiphop=>jazz\n",
      "jazz=>jazz\n",
      "Acc: 5.555555555555555%\n"
     ]
    }
   ],
   "source": [
    "compare_batch(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, epochs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "\"\"\"\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "\"\"\"\n",
    "0\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 8, does not match size of target_names, 10. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fe93b1687dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m print(classification_report(y_test.argmax(axis=1),\n\u001b[1;32m      2\u001b[0m                             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                             target_names=lb.classes_))\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/is_music-genre-recognition-7WxnqNEu/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1541\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 \u001b[0;34m\"parameter\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m             )\n\u001b[1;32m   1545\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 8, does not match size of target_names, 10. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1), \n",
    "                            target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(lb.inverse_transform(y_test), lb.classes_[predictions.argmax(axis=1)], genres)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm = np.around(cm, decimals=2)\n",
    "print(genres)\n",
    "print(cm)\n",
    "print(lb.classes_[predictions.argmax(axis=1)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_array = [[0.34,0.03,0.23,0.08,0.02,0.03,0.02,0.09,0.16,0.01],\n",
    " [0.02, 0.68, 0.02, 0.1 , 0.  , 0.01, 0.04, 0.02, 0.02, 0.08],\n",
    " [0.09, 0.04, 0.63, 0.03, 0.07, 0.02, 0.01, 0.1 , 0.01, 0.  ],\n",
    " [0.  , 0.03, 0.06, 0.67, 0.01, 0.02, 0.05, 0.12, 0.  , 0.04],\n",
    " [0.02, 0.  , 0.06, 0.02, 0.61, 0.1 , 0.01, 0.15, 0.02, 0.  ],\n",
    " [0.  , 0.  , 0.01, 0.  , 0.02, 0.97, 0.  , 0.  , 0.  , 0.  ],\n",
    " [0.02, 0.04, 0.03, 0.03, 0.03, 0.04, 0.58, 0.07, 0.02, 0.15],\n",
    " [0.09, 0.  , 0.06, 0.02, 0.07, 0.02, 0.02, 0.63, 0.09, 0.  ],\n",
    " [0.17, 0.03, 0.01, 0.01, 0.  , 0.  , 0.01, 0.04, 0.71, 0.03],\n",
    " [0.01, 0.12, 0.  , 0.08, 0.  , 0.  , 0.12, 0.02, 0.12, 0.54]]\n",
    "\n",
    "df_cm = pd.DataFrame(p_array, genres,\n",
    "                  genres)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "\n",
    "ax=sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, cmap=\"BuGn\")# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicrec2",
   "language": "python",
   "name": "musicrec2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
